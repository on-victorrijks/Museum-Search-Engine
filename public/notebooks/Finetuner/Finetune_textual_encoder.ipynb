{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf2542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
    "import torch.nn.functional as F\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836b4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Mean length of EN captions: 38.63\n",
      "Mean length of FR captions: 38.618\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordID</th>\n",
       "      <th>task</th>\n",
       "      <th>EN</th>\n",
       "      <th>FR</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>caption</td>\n",
       "      <td>A religious scene features a central figure o...</td>\n",
       "      <td>Une scène religieuse présente une figure centr...</td>\n",
       "      <td>Een religieuze scène toont een centrale figuur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>What objects do you see ?</td>\n",
       "      <td>In the image, there are two people on a cross...</td>\n",
       "      <td>À l'image, il y a deux personnes sur une croix...</td>\n",
       "      <td>In het beeld zijn er twee mensen aan het kruis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>What colors do you see ?</td>\n",
       "      <td>The image features a painting with a predomin...</td>\n",
       "      <td>L'image présente une peinture avec un schéma d...</td>\n",
       "      <td>De afbeelding is voorzien van een schilderij m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>Is this image bright or dark ?</td>\n",
       "      <td>The image is dark.</td>\n",
       "      <td>L'image est sombre.</td>\n",
       "      <td>Het beeld is donker.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>What emotion do you feel when looking at this ...</td>\n",
       "      <td>When looking at this image, I feel a sense of...</td>\n",
       "      <td>En regardant cette image, je ressens un sentim...</td>\n",
       "      <td>Als ik naar dit beeld kijk, voel ik een gevoel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>348</td>\n",
       "      <td>caption</td>\n",
       "      <td>A nude woman in a red dress and a nude man in...</td>\n",
       "      <td>Une femme nue dans une robe rouge et un homme ...</td>\n",
       "      <td>Een naakte vrouw in een rode jurk en een naakt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>348</td>\n",
       "      <td>What objects do you see ?</td>\n",
       "      <td>In the image, there are two men depicted in a...</td>\n",
       "      <td>Dans l'image, il y a deux hommes représentés d...</td>\n",
       "      <td>In het beeld zijn er twee mannen afgebeeld in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>348</td>\n",
       "      <td>What colors do you see ?</td>\n",
       "      <td>The image features a painting with a man and ...</td>\n",
       "      <td>L'image comporte une peinture avec un homme et...</td>\n",
       "      <td>De afbeelding is voorzien van een schilderij m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>348</td>\n",
       "      <td>Is this image bright or dark ?</td>\n",
       "      <td>The image is bright.</td>\n",
       "      <td>L'image est lumineuse.</td>\n",
       "      <td>Het beeld is helder.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>348</td>\n",
       "      <td>What emotion do you feel when looking at this ...</td>\n",
       "      <td>When looking at this image, I feel a sense of...</td>\n",
       "      <td>En regardant cette image, je ressens un sentim...</td>\n",
       "      <td>Als ik naar dit beeld kijk, voel ik een gevoel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     recordID                                               task  \\\n",
       "0          64                                            caption   \n",
       "1          64                          What objects do you see ?   \n",
       "2          64                           What colors do you see ?   \n",
       "3          64                     Is this image bright or dark ?   \n",
       "4          64  What emotion do you feel when looking at this ...   \n",
       "..        ...                                                ...   \n",
       "495       348                                            caption   \n",
       "496       348                          What objects do you see ?   \n",
       "497       348                           What colors do you see ?   \n",
       "498       348                     Is this image bright or dark ?   \n",
       "499       348  What emotion do you feel when looking at this ...   \n",
       "\n",
       "                                                    EN  \\\n",
       "0     A religious scene features a central figure o...   \n",
       "1     In the image, there are two people on a cross...   \n",
       "2     The image features a painting with a predomin...   \n",
       "3                                   The image is dark.   \n",
       "4     When looking at this image, I feel a sense of...   \n",
       "..                                                 ...   \n",
       "495   A nude woman in a red dress and a nude man in...   \n",
       "496   In the image, there are two men depicted in a...   \n",
       "497   The image features a painting with a man and ...   \n",
       "498                               The image is bright.   \n",
       "499   When looking at this image, I feel a sense of...   \n",
       "\n",
       "                                                    FR  \\\n",
       "0    Une scène religieuse présente une figure centr...   \n",
       "1    À l'image, il y a deux personnes sur une croix...   \n",
       "2    L'image présente une peinture avec un schéma d...   \n",
       "3                                  L'image est sombre.   \n",
       "4    En regardant cette image, je ressens un sentim...   \n",
       "..                                                 ...   \n",
       "495  Une femme nue dans une robe rouge et un homme ...   \n",
       "496  Dans l'image, il y a deux hommes représentés d...   \n",
       "497  L'image comporte une peinture avec un homme et...   \n",
       "498                             L'image est lumineuse.   \n",
       "499  En regardant cette image, je ressens un sentim...   \n",
       "\n",
       "                                                    NL  \n",
       "0    Een religieuze scène toont een centrale figuur...  \n",
       "1    In het beeld zijn er twee mensen aan het kruis...  \n",
       "2    De afbeelding is voorzien van een schilderij m...  \n",
       "3                                 Het beeld is donker.  \n",
       "4    Als ik naar dit beeld kijk, voel ik een gevoel...  \n",
       "..                                                 ...  \n",
       "495  Een naakte vrouw in een rode jurk en een naakt...  \n",
       "496  In het beeld zijn er twee mannen afgebeeld in ...  \n",
       "497  De afbeelding is voorzien van een schilderij m...  \n",
       "498                               Het beeld is helder.  \n",
       "499  Als ik naar dit beeld kijk, voel ik een gevoel...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    root = \"/content/drive/MyDrive/MASTER_THESIS/\"\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    df = pd.read_csv(root + \"full_dataset_moondream_captions.csv\")\n",
    "    N = len(df)\n",
    "    BATCH_SIZE = 256\n",
    "    model_path = root + \"MODELS/\"\n",
    "\n",
    "    print(\"Running on Google Colab\")\n",
    "\n",
    "except:\n",
    "    print(\"Running on local machine\")\n",
    "\n",
    "    df = pd.read_csv('../../../private_data/CSV/full_dataset_moondream_captions.csv')\n",
    "    N = 500\n",
    "    BATCH_SIZE = 8\n",
    "    model_path = \"../../../private_data/MODELS/\"\n",
    "#\n",
    "\n",
    "df[\"EN\"] = df[\"EN\"].apply(lambda x: x.split(\"..\")[0])\n",
    "df[\"FR\"] = df[\"FR\"].apply(lambda x: x.split(\"..\")[0])\n",
    "df[\"NL\"] = df[\"NL\"].apply(lambda x: x.split(\"..\")[0])   \n",
    "\n",
    "df[\"EN\"] = df[\"EN\"].apply(lambda x: x.split(\". .\")[0])\n",
    "df[\"FR\"] = df[\"FR\"].apply(lambda x: x.split(\". .\")[0])\n",
    "df[\"NL\"] = df[\"NL\"].apply(lambda x: x.split(\". .\")[0])   \n",
    "\n",
    "df = df.iloc[:N]\n",
    "mean_length_EN = df[\"EN\"].apply(lambda x: len(x.split())).mean()\n",
    "mean_length_FR = df[\"FR\"].apply(lambda x: len(x.split())).mean()\n",
    "print(f\"Mean length of EN captions: {mean_length_EN}\")\n",
    "print(f\"Mean length of FR captions: {mean_length_FR}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe99934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_base = \"openai/clip-vit-large-patch14\"\n",
    "processor = CLIPProcessor.from_pretrained(base_model_base)\n",
    "model = CLIPModel.from_pretrained(base_model_base)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(base_model_base)\n",
    "model_weights_path = model_path + \"art-base.pt\"\n",
    "model.load_state_dict(torch.load(model_weights_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda25612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters with grad: 427616513\n",
      "Number of parameters with grad after freezing: 123060481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getNumberOfParamsWithGrad(model):\n",
    "    num_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params += param.numel()\n",
    "    return num_params\n",
    "\n",
    "nb_params = getNumberOfParamsWithGrad(model)\n",
    "print(f\"Number of parameters with grad: {nb_params}\")\n",
    "\n",
    "# Freeze vision encoder and other non-text layers\n",
    "for name, param in model.named_parameters():\n",
    "    if (\"text_model\" not in name) and (\"logit_scale\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "nb_params = getNumberOfParamsWithGrad(model)\n",
    "print(f\"Number of parameters with grad after freezing: {nb_params}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282c45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8616ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(dataloader, silent=False):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        if silent:\n",
    "            iterator = dataloader\n",
    "        else:\n",
    "            iterator = tqdm(dataloader, desc=\"Computing embeddings\")\n",
    "\n",
    "        for batch in iterator:\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            outputs = model.get_text_features(**inputs)\n",
    "            # Normalize the embeddings\n",
    "            outputs = F.normalize(outputs, p=2, dim=-1)\n",
    "            embeddings.append(outputs.cpu())\n",
    "    return torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae39e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 63/63 [00:01<00:00, 41.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors embeddings shape: torch.Size([8, 768])\n",
      "Boats shape: 1\n",
      "Boat example shape: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 63)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the embeddings of the anchors\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, column):\n",
    "        self.texts = df[column].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "dataset_anchors = TextDataset(df, 'EN')\n",
    "dataloader_anchors = DataLoader(dataset_anchors, batch_size=BATCH_SIZE, shuffle=True)\n",
    "len(dataset_anchors), len(dataloader_anchors)\n",
    "\n",
    "A = compute_embeddings(dataloader_anchors)\n",
    "A.shape\n",
    "\n",
    "class BoatsDataset(Dataset):\n",
    "    def __init__(self, anchors_embeddings, df, columns):\n",
    "        self.boats = [df[col].tolist() for col in columns]\n",
    "        self.size = len(self.boats[0])\n",
    "        self.anchors_embeddings = anchors_embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"anchors_embeddings\": self.anchors_embeddings[idx],\n",
    "            \"boats\": [boat[idx] for boat in self.boats],\n",
    "        }\n",
    "\n",
    "dataset = BoatsDataset(A, df, ['FR']) # , 'NL'\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    anchors_embeddings = batch[\"anchors_embeddings\"]\n",
    "    boats = batch[\"boats\"]\n",
    "    print(f\"Anchors embeddings shape: {anchors_embeddings.shape}\")\n",
    "    print(f\"Boats shape: {len(boats)}\")\n",
    "    boat_example = boats[0]\n",
    "    print(f\"Boat example shape: {len(boat_example)}\")\n",
    "    break\n",
    "\n",
    "len(dataset), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3081ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfAnalysis():\n",
    "    # Compute the mean cosine similarity between the anchor and boat embeddings\n",
    "    def compute_mean_cosine_similarity(anchors_embeddings, boats):\n",
    "        boat_embeddings = compute_embeddings(boats, silent=True)\n",
    "        similarities = []\n",
    "        for anchor_embedding in anchors_embeddings:\n",
    "            similarity = F.cosine_similarity(anchor_embedding, boat_embeddings)\n",
    "            similarities.append(similarity.mean().item())\n",
    "        return sum(similarities) / len(similarities)\n",
    "    \n",
    "    # Compute the mean cosine similarity for each batch\n",
    "    mean_similarities = []\n",
    "    for batch in dataloader:\n",
    "        anchors_embeddings = batch[\"anchors_embeddings\"]\n",
    "        boats = batch[\"boats\"]\n",
    "        mean_similarity = compute_mean_cosine_similarity(anchors_embeddings, boats)\n",
    "        mean_similarities.append(mean_similarity)\n",
    "\n",
    "    # Compute the overall mean cosine similarity\n",
    "    overall_mean_similarity = sum(mean_similarities) / len(mean_similarities)\n",
    "\n",
    "    print(f\"Overall Mean Cosine Similarity: {overall_mean_similarity:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3a7cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing initial performance analysis...\n",
      "Overall Mean Cosine Similarity: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 63/63 [00:05<00:00, 11.59it/s, loss=0.208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Cosine Similarity: 0.3930\n",
      "Epoch 1 - Avg Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 63/63 [00:05<00:00, 11.24it/s, loss=0.0067] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Cosine Similarity: 0.4020\n",
      "Epoch 2 - Avg Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 63/63 [00:05<00:00, 11.48it/s, loss=0.00076] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Cosine Similarity: 0.3973\n",
      "Epoch 3 - Avg Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 63/63 [00:05<00:00, 11.94it/s, loss=0.000575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Cosine Similarity: 0.4019\n",
      "Epoch 4 - Avg Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 63/63 [00:05<00:00, 11.57it/s, loss=0.00105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean Cosine Similarity: 0.4021\n",
      "Epoch 5 - Avg Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def anchor_cosine_loss(anchor_embeddings, text_features):\n",
    "    loss = 1 - F.cosine_similarity(anchor_embeddings, text_features, dim=1)\n",
    "    return loss.mean()\n",
    "\n",
    "def anchor_cosine_margin_loss(anchor_embeddings, text_features, margin=0.3):\n",
    "    cosine_sim = F.cosine_similarity(anchor_embeddings, text_features, dim=1)\n",
    "    # Margin pushes similarity to be > margin\n",
    "    loss = F.relu(margin - cosine_sim)\n",
    "    return loss.mean()\n",
    "\n",
    "N = 5\n",
    "\n",
    "model.eval()\n",
    "print(\"Computing initial performance analysis...\")\n",
    "perfAnalysis()\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(N):\n",
    "    total_loss = 0\n",
    "    tqdm_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{N}\", total=len(dataloader))\n",
    "    i = 0\n",
    "    for batch in tqdm_bar:\n",
    "        # batch: list of 32 elements, each is a list of 3 strings\n",
    "        # Flatten: [\"sent1_en\", \"sent1_fr\", \"sent1_nl\", \"sent2_en\", ...]\n",
    "        others_texts = batch[\"boats\"]\n",
    "        anchors_embeddings = batch[\"anchors_embeddings\"]\n",
    "    \n",
    "        # Flatten others_texts\n",
    "        # Clone anchors_embeddings for each boat\n",
    "        anchors_embeddings_repeated = []\n",
    "        for i in range(len(others_texts)):\n",
    "            anchors_embeddings_repeated.append(anchors_embeddings)\n",
    "        anchors_embeddings_repeated = torch.cat(anchors_embeddings_repeated, dim=0)\n",
    "\n",
    "        boats = [text for sublist in others_texts for text in sublist]\n",
    "\n",
    "        anchors_embeddings = anchors_embeddings_repeated.to(device)\n",
    "\n",
    "        inputs = tokenizer(boats, padding=True, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "        text_features = F.normalize(text_features, dim=1)\n",
    "\n",
    "        # Compute cosine similarity loss for each group\n",
    "        batch_loss = anchor_cosine_margin_loss(anchors_embeddings, text_features)\n",
    "        batch_loss /= len(boats)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "        i += 1 \n",
    "        tqdm_bar.set_postfix(loss=total_loss)\n",
    "\n",
    "    model.eval()\n",
    "    perfAnalysis()\n",
    "    model.train()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    tqdm_bar.close()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Avg Loss: {total_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b866b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the model weights\n",
    "model_weights_path = model_path + \"art-base-TextFT.pt\"\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "#tokenizer.save_pretrained(model_weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
