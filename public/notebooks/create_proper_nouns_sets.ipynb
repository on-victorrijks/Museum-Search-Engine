{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244a3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv \n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c279a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading variables from .env file\n",
    "load_dotenv(\"../../private_data/.env\") \n",
    "\n",
    "# PARENT gets us to the root of the project\n",
    "PARENT = \"./../../\"\n",
    "\n",
    "FOLDER_TABLE = PARENT + os.getenv(\"FOLDER_TABLE\")\n",
    "FILE_FABRITIUS_DATA = PARENT + os.getenv(\"FILE_FABRITIUS_DATA\")\n",
    "FILE_FABRITIUS_DATA_FILTERED = PARENT + os.getenv(\"FILE_FABRITIUS_DATA_FILTERED\")\n",
    "FILE_FABRITIUS_DATA_FILTERED_DOWNLOADED = PARENT + os.getenv(\"FILE_FABRITIUS_DATA_FILTERED_DOWNLOADED\")\n",
    "FOLDER_FIGURES = PARENT + os.getenv(\"FOLDER_FIGURES\")\n",
    "IMAGES_FOLDER = PARENT + os.getenv(\"IMAGES_FOLDER\")\n",
    "\n",
    "DB_INPUT_ARTPIECES = PARENT + os.getenv(\"DB_INPUT_ARTPIECES\")\n",
    "DB_INPUT_ARTISTS = PARENT + os.getenv(\"DB_INPUT_ARTISTS\")\n",
    "\n",
    "BENCHMARK_2_ATTACHED = PARENT + os.getenv(\"BENCHMARK_2_ATTACHED\")\n",
    "BENCHMARK_2_EXPLODED = PARENT + os.getenv(\"BENCHMARK_2_EXPLODED\")\n",
    "\n",
    "FILE_SUBJECTMATTERS_PARSED = PARENT + os.getenv(\"FILE_SUBJECTMATTERS_PARSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28c8b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixPath(path):\n",
    "    return path.replace(\".././\", \"../\")\n",
    "\n",
    "filtered_data_downloaded = pd.read_csv(FILE_FABRITIUS_DATA_FILTERED_DOWNLOADED)\n",
    "\n",
    "def get_image_path_from_recordID(recordID):\n",
    "    \"\"\"\n",
    "    Given a recordID, return the local path for its image.\n",
    "    \"\"\"\n",
    "    # Locate row in the downloaded DataFrame\n",
    "    paths = filtered_data_downloaded[\n",
    "        filtered_data_downloaded[\"recordID\"] == recordID\n",
    "    ][\"low_res_filename\"].values\n",
    "    \n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "    \n",
    "    path = paths[0]\n",
    "    # Merge: IMAGES_FOLDER + path[1:]\n",
    "    merged_path = fixPath(os.path.join(IMAGES_FOLDER, path[1:]))\n",
    "    return merged_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451b0d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the artworks data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ARTWORKS \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(DB_INPUT_ARTPIECES)\n\u001b[0;32m      3\u001b[0m ARTWORKS\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the artworks data\n",
    "ARTWORKS = pd.read_csv(DB_INPUT_ARTPIECES)\n",
    "ARTWORKS.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc46ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creatorID</th>\n",
       "      <th>creatorLastName</th>\n",
       "      <th>creatorFirstName</th>\n",
       "      <th>creatorBirthAndDeathDescription</th>\n",
       "      <th>creatorNationality</th>\n",
       "      <th>creatorDeathDate</th>\n",
       "      <th>creatorBirthDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auth:509:309</td>\n",
       "      <td>Bouts</td>\n",
       "      <td>Dirk</td>\n",
       "      <td>Haarlem (Pays-Bas) vers 1410 ? - Louvain 1475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>1410.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      creatorID creatorLastName creatorFirstName  \\\n",
       "0  Auth:509:309           Bouts             Dirk   \n",
       "\n",
       "                 creatorBirthAndDeathDescription creatorNationality  \\\n",
       "0  Haarlem (Pays-Bas) vers 1410 ? - Louvain 1475                NaN   \n",
       "\n",
       "   creatorDeathDate  creatorBirthDate  \n",
       "0            1475.0            1410.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the artworks data\n",
    "ARTISTS = pd.read_csv(DB_INPUT_ARTISTS)\n",
    "ARTISTS.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9152fee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordID_to_index = {}\n",
    "for i, recordID in enumerate(ARTWORKS[\"recordID\"]):\n",
    "    recordID_to_index[recordID] = i\n",
    "len(recordID_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b2319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectmatter_json = json.loads(open(FILE_SUBJECTMATTERS_PARSED, \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "# dict_keys()\n",
    "def get_structured_flattened(recordID):\n",
    "\n",
    "    index = recordID_to_index[recordID]\n",
    "\n",
    "    proper_nouns = set()\n",
    "    for key in ['subjectMatterSubjectTerms', 'subjectMatterIconographicTerms', 'subjectMatterConceptualTerms']:\n",
    "        proper_nouns.update(subjectmatter_json[index][\"structured\"][key][\"flattened\"])\n",
    "\n",
    "    # Remove words that do not start with a capital letter\n",
    "    proper_nouns = [word for word in proper_nouns if word[0].isupper()]\n",
    "\n",
    "    return proper_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25b8a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5301/5301 [00:00<00:00, 331272.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordID</th>\n",
       "      <th>proper_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>[Jésus, Nouveau Testament, Passion, Evangiles,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>[Louise van der Hecht]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>[Robert Schumann]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>[Marguerite Khnopff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>[Cupidon, Ariane, Bacchus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>11252</td>\n",
       "      <td>[Namur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>11521</td>\n",
       "      <td>[Andromède, Persée, Céto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>11525</td>\n",
       "      <td>[Nicolas-Henri Tardieu, Marie-Anne Hortemels]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>11533</td>\n",
       "      <td>[Rik Wouters, Nel Wouters, Amsterdam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>11638</td>\n",
       "      <td>[Périclès Pantazis]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1905 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordID                                       proper_nouns\n",
       "0           64  [Jésus, Nouveau Testament, Passion, Evangiles,...\n",
       "1           78                             [Louise van der Hecht]\n",
       "2           79                                  [Robert Schumann]\n",
       "3           81                               [Marguerite Khnopff]\n",
       "4          105                         [Cupidon, Ariane, Bacchus]\n",
       "...        ...                                                ...\n",
       "1900     11252                                            [Namur]\n",
       "1901     11521                          [Andromède, Persée, Céto]\n",
       "1902     11525      [Nicolas-Henri Tardieu, Marie-Anne Hortemels]\n",
       "1903     11533              [Rik Wouters, Nel Wouters, Amsterdam]\n",
       "1904     11638                                [Périclès Pantazis]\n",
       "\n",
       "[1905 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_nouns_per_recordID = {}\n",
    "for recordID in tqdm(ARTWORKS[\"recordID\"]):\n",
    "    proper_nouns = get_structured_flattened(recordID)\n",
    "    proper_nouns_per_recordID[recordID] = proper_nouns\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "proper_nouns_df = pd.DataFrame(columns=[\"recordID\", \"proper_nouns\"])\n",
    "proper_nouns_df[\"recordID\"] = proper_nouns_per_recordID.keys()\n",
    "proper_nouns_df[\"proper_nouns\"] = proper_nouns_per_recordID.values()\n",
    "# Keep only the rows with proper nouns\n",
    "proper_nouns_df = proper_nouns_df[proper_nouns_df[\"proper_nouns\"].str.len() > 0]\n",
    "proper_nouns_df.reset_index(drop=True, inplace=True)\n",
    "proper_nouns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad50ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\") # All tokenizer tokenize the same \n",
    "\n",
    "def get_tokenized_text(text):\n",
    "    return len(tokenizer(text)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d707da6",
   "metadata": {},
   "source": [
    "# -ATTACHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dbc8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordID: 64\n",
      "proper_nouns: Jésus, Nouveau Testament, Passion, Evangiles, Vierge, Christ, Calvaire, Crucifixion, Jérusalem\n",
      "tokenized_length: 31\n"
     ]
    }
   ],
   "source": [
    "attached_dataset = proper_nouns_df.copy()\n",
    "attached_dataset[\"proper_nouns\"] = proper_nouns_df[\"proper_nouns\"].apply(lambda x: \", \".join(x))\n",
    "attached_dataset[\"tokenized_length\"] = attached_dataset[\"proper_nouns\"].apply(get_tokenized_text)\n",
    "\n",
    "# Remove rows with tokenized length > 75\n",
    "attached_dataset = attached_dataset[attached_dataset[\"tokenized_length\"] <= 75]\n",
    "attached_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "attached_dataset.to_csv(BENCHMARK_2_ATTACHED, index=False)\n",
    "\n",
    "columns = list(attached_dataset.columns)\n",
    "example_row = attached_dataset.iloc[0]\n",
    "for column in columns:\n",
    "    print(f\"{column}: {example_row[column]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ced4e",
   "metadata": {},
   "source": [
    "# -EXPLODED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d5c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proper_nouns: Afrique\n",
      "recordID: [137, 717, 1465, 1848, 1849, 1854, 4672, 6163, 6164, 6165, 6166, 6167, 6168, 6460, 6462, 6463, 6464, 8445, 8720]\n"
     ]
    }
   ],
   "source": [
    "exploded_dataset = proper_nouns_df.copy()\n",
    "exploded_dataset = exploded_dataset.explode(\"proper_nouns\")\n",
    "\n",
    "exploded_dataset = exploded_dataset.groupby(\"proper_nouns\")[\"recordID\"].apply(list).reset_index()\n",
    "\n",
    "exploded_dataset.to_csv(BENCHMARK_2_EXPLODED, index=False)\n",
    "\n",
    "columns = list(exploded_dataset.columns)\n",
    "example_row_index = 0\n",
    "while True:\n",
    "    example_row = exploded_dataset.iloc[example_row_index]\n",
    "    if len(example_row[\"recordID\"]) > 10:\n",
    "        break\n",
    "    example_row_index += 1\n",
    "for column in columns:\n",
    "    print(f\"{column}: {example_row[column]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
