{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libvips42 libvips-dev\n",
    "!pip install pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/content/drive/MyDrive/MASTER_THESIS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET = pd.read_csv(root + \"private_data/CSV/fabritius_data_filtered_downloaded.csv\")\n",
    "# Remove rows with corrupted images\n",
    "FULL_DATASET = FULL_DATASET[FULL_DATASET[\"recordID\"] != 11546]\n",
    "FULL_DATASET = FULL_DATASET[FULL_DATASET[\"recordID\"] != 5262]\n",
    "FULL_DATASET = FULL_DATASET.sample(frac=1.0).reset_index(drop=True)\n",
    "FULL_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixPath(path):\n",
    "    return path.replace(\".././\", \"../\")\n",
    "\n",
    "def get_image_path_from_recordID(dataset, recordID):\n",
    "    \"\"\"\n",
    "    Given a recordID, return the local path for its image.\n",
    "    \"\"\"\n",
    "    # Locate row in the downloaded DataFrame\n",
    "    paths = dataset[\n",
    "        dataset[\"recordID\"] == recordID\n",
    "    ][\"low_res_filename\"].values\n",
    "    \n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "    \n",
    "    path = paths[0]\n",
    "    # Merge: IMAGES_FOLDER + path[1:]\n",
    "    merged_path = fixPath(root + \"images/\" + path[1:])\n",
    "    return merged_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, dataframe, getImageFromRecordID):\n",
    "        self.dataframe = dataframe\n",
    "        self.getImageFromRecordID = getImageFromRecordID\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        \n",
    "        recordID = row['recordID']\n",
    "\n",
    "        path = self.getImageFromRecordID(self.dataframe, recordID) \n",
    "        image = Image.open(path)        \n",
    "\n",
    "        return recordID, image\n",
    "    \n",
    "# Test\n",
    "dataset = ImageTextDataset(FULL_DATASET, get_image_path_from_recordID)\n",
    "dalaloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "for recordIDs, images in dalaloader:\n",
    "    print(len(recordIDs), len(images))\n",
    "    plt.imshow(images[0], cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "T_tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "T_model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2025-01-09\"  # Pin to specific version\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    revision=revision,\n",
    "    device_map={\"\": \"cuda\"}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Animal Bird, Butterfly, Cat, Chicken, Cow, Dog, Donkey, Fish, Horse, Insect, Mouse, Rabbit, Reptile, Sheep\n",
    "Architecture Bridge, Castle, Church, Door, House, Mill, Pillar, Staircase, Window\n",
    "Christianity Angel, Cross, Devil, God, Jesus Christ, Saint, Virgin Mary\n",
    "Clothing Bag, Belt, Cane, Crown, Dress, Gloves, Hat, Jewellery, Mask, Shoes, Tie, Umbrella\n",
    "Food Apple, Banana, Bread, Cheese, Grapes, Lobster, Orange, Pineapple, Vegetable, Watermelon, Wine\n",
    "Furniture Bathtub, Bed, Chair, Easel, Sofa, Table\n",
    "Human Baby, Child, Face, Hand, Man, Woman\n",
    "Instrument Drum, Flute, Guitar, Harp, Piano, Violin\n",
    "Interior Bird Cage, Book, Bottle, Bow, Cup, Drapery, Flag, Globe, Lamp, Mirror, Paper, Vase\n",
    "Nature Bush, Cloud, Fire, Flower, Lake, Lightning, Moon, Mountain, Plant, Rock, Sea, Sky, Sun, Tree\n",
    "Occultism Demon, Ghost, Skeleton, Skull, Star\n",
    "Vehicle Airplane, Bicycle, Boat, Car, Carriage, Ship, Train, Wheel\n",
    "Weaponry Armor, Arrow, Bow, Firearm, Hammer, Helmet, Rope, Shield, Spear, Sword,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectsList = [\n",
    "    \"man\",\n",
    "    \"woman\",\n",
    "    \"tree\",\n",
    "    \"house\",\n",
    "    \"sea\",\n",
    "    \"river\",\n",
    "    \"sun\",\n",
    "    \"flower\",\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"bird\",\n",
    "    \"horse\",\n",
    "    \"chicken\",\n",
    "    \"castle\",\n",
    "    \"church\",\n",
    "    \"door\",\n",
    "    \"moutain\",\n",
    "    \"cloud\",\n",
    "    \"boat\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveOutputs(outputs):\n",
    "    with open(root + \"outputs.json\", \"w\") as f:\n",
    "        json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "\n",
    "batch_index = 0\n",
    "for recordIDs, images in dalaloader:\n",
    "    # Get captions\n",
    "    captions_EN = model.caption(images, length=\"short\")[\"caption\"]\n",
    "    # Get translated captions\n",
    "    inputs = T_tokenizer(captions_EN, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Perform translation\n",
    "    translated = T_model.generate(**inputs)\n",
    "    # Decode the translated text\n",
    "    captions_FR = T_tokenizer.decode(translated, skip_special_tokens=True)\n",
    "    # Get objects\n",
    "    objsOutputs = {}\n",
    "    for obj in objectsList:\n",
    "        objsOutputs[obj] = model.detect(images, obj)[\"objects\"]\n",
    "    # Save outputs\n",
    "    for i, recordID in enumerate(recordIDs):\n",
    "        outputs[recordID] = {\n",
    "            \"caption_EN\": captions_EN[i],\n",
    "            \"caption_FR\": captions_FR[i],\n",
    "            \"objects\": [objsOutputs[obj][i] for obj in objectsList]\n",
    "        }\n",
    "\n",
    "    batch_index += 1\n",
    "\n",
    "    if batch_index % 10 == 0:\n",
    "        saveOutputs(outputs)\n",
    "\n",
    "    break\n",
    "\n",
    "print(len(outputs))\n",
    "\n",
    "saveOutputs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
