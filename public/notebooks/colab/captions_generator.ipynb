{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libvips42 libvips-dev\n",
    "!pip install pyvips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/content/drive/MyDrive/MASTER_THESIS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET = pd.read_csv(root + \"fabritius_data_filtered_downloaded.csv\")\n",
    "# Remove rows with corrupted images\n",
    "FULL_DATASET = FULL_DATASET[FULL_DATASET[\"recordID\"] != 11546]\n",
    "FULL_DATASET = FULL_DATASET[FULL_DATASET[\"recordID\"] != 5262]\n",
    "FULL_DATASET = FULL_DATASET.sample(frac=1.0).reset_index(drop=True)\n",
    "FULL_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOutputs():\n",
    "  return pd.read_csv(root + \"outputs.csv\")\n",
    "\n",
    "def saveOutputs(df):\n",
    "  df.to_csv(root + \"outputs.csv\", index=False)\n",
    "\n",
    "if os.path.exists(root + \"outputs.csv\"):\n",
    "    captions = loadOutputs()\n",
    "else:\n",
    "    captions = pd.DataFrame(columns=[\"recordID\", \"question\", \"caption_EN\", \"caption_FR\"])\n",
    "\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_recordIDs = captions[\"recordID\"].unique()\n",
    "FULL_DATASET = FULL_DATASET[~FULL_DATASET[\"recordID\"].isin(done_recordIDs)]\n",
    "FULL_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixPath(path):\n",
    "    return path.replace(\".././\", \"../\")\n",
    "\n",
    "def get_image_path_from_recordID(dataset, recordID):\n",
    "    \"\"\"\n",
    "    Given a recordID, return the local path for its image.\n",
    "    \"\"\"\n",
    "    # Locate row in the downloaded DataFrame\n",
    "    paths = dataset[\n",
    "        dataset[\"recordID\"] == recordID\n",
    "    ][\"low_res_filename\"].values\n",
    "\n",
    "    if len(paths) == 0:\n",
    "        return None\n",
    "\n",
    "    path = paths[0]\n",
    "    # Merge: IMAGES_FOLDER + path[1:]\n",
    "    merged_path = fixPath(root + \"images/\" + path[1:])\n",
    "    return merged_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, dataframe, getImageFromRecordID):\n",
    "        self.dataframe = dataframe\n",
    "        self.getImageFromRecordID = getImageFromRecordID\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        recordID = row['recordID']\n",
    "\n",
    "        path = self.getImageFromRecordID(self.dataframe, recordID)\n",
    "        path = path.replace(\"internet\", \"Internet\")\n",
    "        path = path.replace(\"Mod\", \"mod\")\n",
    "        path = path.replace(\"Old\", \"old\")\n",
    "        path = path.replace(\"Stefaan\", \"stefaan\")\n",
    "        path = path.replace(\"Art-Foto\", \"art-foto\")\n",
    "        image = Image.open(path)\n",
    "\n",
    "        return recordID, image\n",
    "\n",
    "import os\n",
    "# Verify that all image paths exist\n",
    "for recordID, path in tqdm.tqdm(zip(FULL_DATASET[\"recordID\"], FULL_DATASET[\"low_res_filename\"])):\n",
    "    path = get_image_path_from_recordID(FULL_DATASET, recordID)\n",
    "    path = path.replace(\"internet\", \"Internet\")\n",
    "    path = path.replace(\"Mod\", \"mod\")\n",
    "    path = path.replace(\"Old\", \"old\")\n",
    "    path = path.replace(\"Stefaan\", \"stefaan\")\n",
    "    path = path.replace(\"Art-Foto\", \"art-foto\")\n",
    "    assert os.path.exists(path), f\"Image file not found: {path}\"\n",
    "\n",
    "# Test\n",
    "dataset = ImageTextDataset(FULL_DATASET, get_image_path_from_recordID)\n",
    "dalaloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "for recordIDs, images in dalaloader:\n",
    "    print(len(recordIDs), len(images))\n",
    "    plt.imshow(images[0], cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "T_tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "T_model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# English to French translation function\n",
    "def translate_to_french(text):\n",
    "    # Tokenize input text\n",
    "    inputs = T_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Perform translation\n",
    "    translated = T_model.generate(**inputs)\n",
    "    # Decode the translated text\n",
    "    return T_tokenizer.decode(translated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2025-01-09\"  # Pin to specific version\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    revision=revision,\n",
    "    device_map={\"\": \"cuda\"}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is a short caption for this image where you speak about objects ?\",\n",
    "    \"What is a short caption for this image where you speak about colors ?\",\n",
    "    \"What is a short caption for this image where you speak about luminosity ?\",\n",
    "    \"What is a short caption for this image where you speak about emotions ?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRow(df, recordID, question, caption_EN, caption_FR):\n",
    "    df.loc[len(df)] = [recordID, question, caption_EN, caption_FR]\n",
    "\n",
    "batch_index = 0\n",
    "for recordIDs, images in tqdm.tqdm(dalaloader):\n",
    "    # Get captions\n",
    "    for index, recordID in enumerate(recordIDs):\n",
    "      if recordID in captions[\"recordID\"].values:\n",
    "        continue\n",
    "\n",
    "      image = images[index]\n",
    "\n",
    "      # Classic short caption\n",
    "      caption_EN = model.caption(image, length=\"short\")[\"caption\"]\n",
    "      caption_FR = translate_to_french(caption_EN)\n",
    "\n",
    "      # Get additional captions using questions\n",
    "      questionsOutputs = []\n",
    "      for question in questions:\n",
    "        answer_EN = model.query(image, question)[\"answer\"]\n",
    "        answer_FR = translate_to_french(answer_EN)\n",
    "        questionsOutputs.append((question, answer_EN, answer_FR))\n",
    "\n",
    "      # Add all at once\n",
    "      addRow(captions, recordID, \"caption\", caption_EN, caption_FR)\n",
    "      for question, answer_EN, answer_FR in questionsOutputs:\n",
    "        addRow(captions, recordID, question, answer_EN, answer_FR)\n",
    "\n",
    "    batch_index += 1\n",
    "\n",
    "    if batch_index % 3 == 0:\n",
    "        saveOutputs(captions)\n",
    "\n",
    "saveOutputs(captions)\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordID = captions[\"recordID\"][0]\n",
    "rows = captions[captions[\"recordID\"] == recordID]\n",
    "for question, cEN, cFR in zip(rows[\"question\"], rows[\"caption_EN\"], rows[\"caption_FR\"]):\n",
    "  print(question)\n",
    "  print(cFR)\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
