{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5f8bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747314761040,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "6bb5f8bb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from dotenv import load_dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10882c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# loading variables from .env file\n",
    "load_dotenv(\"../../private_data/.env\") \n",
    "\n",
    "# PARENT gets us to the root of the project\n",
    "PARENT = \"./../../\"\n",
    "\n",
    "FOLDER_TABLE = PARENT + os.getenv(\"FOLDER_TABLE\")\n",
    "FILE_FABRITIUS_DATA = PARENT + os.getenv(\"FILE_FABRITIUS_DATA\")\n",
    "FILE_FABRITIUS_DATA_FILTERED = PARENT + os.getenv(\"FILE_FABRITIUS_DATA_FILTERED\")\n",
    "FILE_FABRITIUS_DATA_FILTERED_DOWNLOADED = PARENT + os.getenv(\"FILE_FABRITIUS_DATA_FILTERED_DOWNLOADED\")\n",
    "FOLDER_FIGURES = PARENT + os.getenv(\"FOLDER_FIGURES\")\n",
    "IMAGES_FOLDER = PARENT + os.getenv(\"IMAGES_FOLDER\")\n",
    "\n",
    "DB_INPUT_ARTPIECES = PARENT + os.getenv(\"DB_INPUT_ARTPIECES\")\n",
    "DB_INPUT_ARTISTS = PARENT + os.getenv(\"DB_INPUT_ARTISTS\")\n",
    "\n",
    "BENCHMARK_1 = PARENT + os.getenv(\"BENCHMARK_1\")\n",
    "\n",
    "FILE_SUBJECTMATTERS_PARSED = PARENT + os.getenv(\"FILE_SUBJECTMATTERS_PARSED\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f6089f",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1747314762212,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "a9f6089f"
   },
   "outputs": [],
   "source": [
    "# Get the artworks data\n",
    "ARTWORKS = pd.read_csv(DB_INPUT_ARTPIECES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9030027",
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1747314762490,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "c9030027"
   },
   "outputs": [],
   "source": [
    "# Methods to get an image from a recordID\n",
    "def fixPath(path):\n",
    "    return path.replace(\".././\", \"../\")\n",
    "\n",
    "recordID_to_imageLowResFilename = {}\n",
    "for index, row in ARTWORKS.iterrows():\n",
    "    recordID = row[\"recordID\"]\n",
    "    path = row[\"imageLowResFilename\"]\n",
    "\n",
    "    # Fix the imageLowResFilename\n",
    "    path = fixPath(IMAGES_FOLDER + path[1:])\n",
    "\n",
    "    path = path.replace(\"internet\", \"Internet\")\n",
    "    path = path.replace(\"Mod\", \"mod\")\n",
    "    path = path.replace(\"MOD\", \"mod\")\n",
    "    path = path.replace(\"Old\", \"old\")\n",
    "    path = path.replace(\"Stefaan\", \"stefaan\")\n",
    "    path = path.replace(\"Art-Foto\", \"art-foto\")\n",
    "    path = path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "    recordID_to_imageLowResFilename[recordID] = path\n",
    "\n",
    "# Test it\n",
    "for recordID, path in recordID_to_imageLowResFilename.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Path does not exist: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb34820f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1747314762691,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "fb34820f",
    "outputId": "2bf6a821-6548-40f8-f058-cda5ec248863"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordID</th>\n",
       "      <th>category</th>\n",
       "      <th>focus</th>\n",
       "      <th>caption_fr</th>\n",
       "      <th>caption_en</th>\n",
       "      <th>caption_nl</th>\n",
       "      <th>additional_info_fr</th>\n",
       "      <th>additional_info_en</th>\n",
       "      <th>additional_info_nl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8291</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>colors</td>\n",
       "      <td>Une vieille femme sans abri au coin d'une rue,...</td>\n",
       "      <td>An old homeless woman at the corner of a stree...</td>\n",
       "      <td>Een oude dakloze vrouw op de hoek van een stra...</td>\n",
       "      <td>[Couleurs sombres]</td>\n",
       "      <td>[Dark colors]</td>\n",
       "      <td>[Donkere kleuren]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4996</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>content</td>\n",
       "      <td>Un portrait d'une femme en robe avec un chapea...</td>\n",
       "      <td>A portrait of a woman in a dress with a hat, a...</td>\n",
       "      <td>Een portret van een vrouw in een jurk met een ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10795</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>emotion</td>\n",
       "      <td>Ferme le long d'un ruisseau où des vaches boie...</td>\n",
       "      <td>Closes along a stream where cows drink, trees,...</td>\n",
       "      <td>Sluit langs een beekje waar koeien drinken, bo...</td>\n",
       "      <td>[Émotion neutre, Émotion joie]</td>\n",
       "      <td>[Neutral emotion, Joy emotion]</td>\n",
       "      <td>[Emotie neutraal, Vreugde-emotie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1820</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Un femme avec un voile et un baton prie en reg...</td>\n",
       "      <td>A woman with a veil and a baton prays looking ...</td>\n",
       "      <td>Een vrouw met een sluier en een stokje bidt na...</td>\n",
       "      <td>[Luminosité sombre]</td>\n",
       "      <td>[Dark luminosity]</td>\n",
       "      <td>[Donkere helderheid]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordID category       focus  \\\n",
       "0      8291  Tableau      colors   \n",
       "1      4996  Tableau     content   \n",
       "2     10795  Tableau     emotion   \n",
       "3      1820  Tableau  luminosity   \n",
       "\n",
       "                                          caption_fr  \\\n",
       "0  Une vieille femme sans abri au coin d'une rue,...   \n",
       "1  Un portrait d'une femme en robe avec un chapea...   \n",
       "2  Ferme le long d'un ruisseau où des vaches boie...   \n",
       "3  Un femme avec un voile et un baton prie en reg...   \n",
       "\n",
       "                                          caption_en  \\\n",
       "0  An old homeless woman at the corner of a stree...   \n",
       "1  A portrait of a woman in a dress with a hat, a...   \n",
       "2  Closes along a stream where cows drink, trees,...   \n",
       "3  A woman with a veil and a baton prays looking ...   \n",
       "\n",
       "                                          caption_nl  \\\n",
       "0  Een oude dakloze vrouw op de hoek van een stra...   \n",
       "1  Een portret van een vrouw in een jurk met een ...   \n",
       "2  Sluit langs een beekje waar koeien drinken, bo...   \n",
       "3  Een vrouw met een sluier en een stokje bidt na...   \n",
       "\n",
       "               additional_info_fr              additional_info_en  \\\n",
       "0              [Couleurs sombres]                   [Dark colors]   \n",
       "1                             NaN                             NaN   \n",
       "2  [Émotion neutre, Émotion joie]  [Neutral emotion, Joy emotion]   \n",
       "3             [Luminosité sombre]               [Dark luminosity]   \n",
       "\n",
       "                  additional_info_nl  \n",
       "0                  [Donkere kleuren]  \n",
       "1                                NaN  \n",
       "2  [Emotie neutraal, Vreugde-emotie]  \n",
       "3               [Donkere helderheid]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def v_literal_eval(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan\n",
    "DATA = pd.read_csv(BENCHMARK_1, converters={'additional_info_fr': v_literal_eval, 'additional_info_en': v_literal_eval, 'additional_info_nl': v_literal_eval})\n",
    "unique_focus = DATA['focus'].unique()\n",
    "example_df = None\n",
    "for focus in unique_focus:\n",
    "    focus_data = DATA[DATA['focus'] == focus]\n",
    "    if example_df is None:\n",
    "        example_df = focus_data.sample(1)\n",
    "    else:\n",
    "        example_df = pd.concat([example_df, focus_data.sample(1)], ignore_index=True)\n",
    "\n",
    "example_df.drop(columns=['tokenized_length_fr', 'tokenized_length_en', 'tokenized_length_nl'], inplace=True)\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58029c6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1747314762977,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "58029c6a",
    "outputId": "eb73bb1e-dca2-4692-e8ec-874a4bc219a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordID</th>\n",
       "      <th>category</th>\n",
       "      <th>focus</th>\n",
       "      <th>caption_fr</th>\n",
       "      <th>caption_en</th>\n",
       "      <th>caption_nl</th>\n",
       "      <th>additional_info_fr</th>\n",
       "      <th>additional_info_en</th>\n",
       "      <th>additional_info_nl</th>\n",
       "      <th>tokenized_length_fr</th>\n",
       "      <th>tokenized_length_en</th>\n",
       "      <th>tokenized_length_nl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10869</td>\n",
       "      <td>Dessin</td>\n",
       "      <td>colors</td>\n",
       "      <td>Un prêtre prononce un sermon les mains écartée...</td>\n",
       "      <td>A priest delivers a sermon with his hands apar...</td>\n",
       "      <td>Een priester geeft een preek met zijn handen u...</td>\n",
       "      <td>[Bicolore, Couleur rouge]</td>\n",
       "      <td>[Bicolor, Red color]</td>\n",
       "      <td>[Bicolor, Rode kleur]</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6146</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>colors</td>\n",
       "      <td>Un homme, contre une charette, une femme assis...</td>\n",
       "      <td>A man, against a charette, a woman sitting on ...</td>\n",
       "      <td>Een man, tegen een charette, een vrouw die op ...</td>\n",
       "      <td>[Couleurs vives, Couleur verte]</td>\n",
       "      <td>[Bright colors, Green color]</td>\n",
       "      <td>[Heldere kleuren, Groene kleur]</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>959</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>colors</td>\n",
       "      <td>Un portrait d'une femme avec un habit bleu et ...</td>\n",
       "      <td>A portrait of a woman with a blue and white dr...</td>\n",
       "      <td>Een portret van een vrouw met een blauwe en wi...</td>\n",
       "      <td>[Couleur neutre]</td>\n",
       "      <td>[Neutral color]</td>\n",
       "      <td>[Neutrale kleur]</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>579</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>colors</td>\n",
       "      <td>Portrait d'une jeune femme avec des cheveux no...</td>\n",
       "      <td>Portrait of a young woman with black hair, whi...</td>\n",
       "      <td>Portret van een jonge vrouw met zwart haar, wi...</td>\n",
       "      <td>[Couleur noir et blanc]</td>\n",
       "      <td>[Black and white color]</td>\n",
       "      <td>[Zwart-wit kleur]</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10351</td>\n",
       "      <td>Dessin</td>\n",
       "      <td>colors</td>\n",
       "      <td>Un dessin d'un personnage couché avec un habit...</td>\n",
       "      <td>A drawing of a character lying with a large dr...</td>\n",
       "      <td>Een tekening van een personage liggend met een...</td>\n",
       "      <td>[Couleur noir et blanc]</td>\n",
       "      <td>[Black and white color]</td>\n",
       "      <td>[Zwart-wit kleur]</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>1488</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Une place avec une foule vêtue de noir, une fe...</td>\n",
       "      <td>A place with a crowd dressed in black, a woman...</td>\n",
       "      <td>Een plek met een menigte gekleed in het zwart,...</td>\n",
       "      <td>[Luminosité lumineuse]</td>\n",
       "      <td>[Bright luminosity]</td>\n",
       "      <td>[Heldere helderheid]</td>\n",
       "      <td>61</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1724</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Un foule qui fait la fête en extérieur, vêteme...</td>\n",
       "      <td>A crowd partying outside, colorful clothes, vi...</td>\n",
       "      <td>Een menigte feesten buiten, kleurrijke kleren,...</td>\n",
       "      <td>[Luminosité neutre]</td>\n",
       "      <td>[Neutral luminosity]</td>\n",
       "      <td>[Neutrale helderheid]</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>7059</td>\n",
       "      <td>Dessin</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Un texte entouré d'enfants anges avec des femm...</td>\n",
       "      <td>A text surrounded by children angels with nake...</td>\n",
       "      <td>Een tekst omringd door kinderen engelen met na...</td>\n",
       "      <td>[Luminosité lumineuse]</td>\n",
       "      <td>[Bright luminosity]</td>\n",
       "      <td>[Heldere helderheid]</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>8081</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Un homme torse nu et un homme avec un habit bl...</td>\n",
       "      <td>A man with a naked torso and a man with a blue...</td>\n",
       "      <td>Een man met een naakte romp en een man met een...</td>\n",
       "      <td>[Luminosité neutre]</td>\n",
       "      <td>[Neutral luminosity]</td>\n",
       "      <td>[Neutrale helderheid]</td>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1352</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>Une maison dans une forêt aux arbres sombres, ...</td>\n",
       "      <td>A house in a forest with dark trees, a pontoon...</td>\n",
       "      <td>Een huis in een bos met donkere bomen, een pon...</td>\n",
       "      <td>[Luminosité sombre]</td>\n",
       "      <td>[Dark luminosity]</td>\n",
       "      <td>[Donkere helderheid]</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1816 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recordID category       focus  \\\n",
       "0        10869   Dessin      colors   \n",
       "1         6146  Tableau      colors   \n",
       "2          959  Tableau      colors   \n",
       "3          579  Tableau      colors   \n",
       "4        10351   Dessin      colors   \n",
       "...        ...      ...         ...   \n",
       "1811      1488  Tableau  luminosity   \n",
       "1812      1724  Tableau  luminosity   \n",
       "1813      7059   Dessin  luminosity   \n",
       "1814      8081  Tableau  luminosity   \n",
       "1815      1352  Tableau  luminosity   \n",
       "\n",
       "                                             caption_fr  \\\n",
       "0     Un prêtre prononce un sermon les mains écartée...   \n",
       "1     Un homme, contre une charette, une femme assis...   \n",
       "2     Un portrait d'une femme avec un habit bleu et ...   \n",
       "3     Portrait d'une jeune femme avec des cheveux no...   \n",
       "4     Un dessin d'un personnage couché avec un habit...   \n",
       "...                                                 ...   \n",
       "1811  Une place avec une foule vêtue de noir, une fe...   \n",
       "1812  Un foule qui fait la fête en extérieur, vêteme...   \n",
       "1813  Un texte entouré d'enfants anges avec des femm...   \n",
       "1814  Un homme torse nu et un homme avec un habit bl...   \n",
       "1815  Une maison dans une forêt aux arbres sombres, ...   \n",
       "\n",
       "                                             caption_en  \\\n",
       "0     A priest delivers a sermon with his hands apar...   \n",
       "1     A man, against a charette, a woman sitting on ...   \n",
       "2     A portrait of a woman with a blue and white dr...   \n",
       "3     Portrait of a young woman with black hair, whi...   \n",
       "4     A drawing of a character lying with a large dr...   \n",
       "...                                                 ...   \n",
       "1811  A place with a crowd dressed in black, a woman...   \n",
       "1812  A crowd partying outside, colorful clothes, vi...   \n",
       "1813  A text surrounded by children angels with nake...   \n",
       "1814  A man with a naked torso and a man with a blue...   \n",
       "1815  A house in a forest with dark trees, a pontoon...   \n",
       "\n",
       "                                             caption_nl  \\\n",
       "0     Een priester geeft een preek met zijn handen u...   \n",
       "1     Een man, tegen een charette, een vrouw die op ...   \n",
       "2     Een portret van een vrouw met een blauwe en wi...   \n",
       "3     Portret van een jonge vrouw met zwart haar, wi...   \n",
       "4     Een tekening van een personage liggend met een...   \n",
       "...                                                 ...   \n",
       "1811  Een plek met een menigte gekleed in het zwart,...   \n",
       "1812  Een menigte feesten buiten, kleurrijke kleren,...   \n",
       "1813  Een tekst omringd door kinderen engelen met na...   \n",
       "1814  Een man met een naakte romp en een man met een...   \n",
       "1815  Een huis in een bos met donkere bomen, een pon...   \n",
       "\n",
       "                   additional_info_fr            additional_info_en  \\\n",
       "0           [Bicolore, Couleur rouge]          [Bicolor, Red color]   \n",
       "1     [Couleurs vives, Couleur verte]  [Bright colors, Green color]   \n",
       "2                    [Couleur neutre]               [Neutral color]   \n",
       "3             [Couleur noir et blanc]       [Black and white color]   \n",
       "4             [Couleur noir et blanc]       [Black and white color]   \n",
       "...                               ...                           ...   \n",
       "1811           [Luminosité lumineuse]           [Bright luminosity]   \n",
       "1812              [Luminosité neutre]          [Neutral luminosity]   \n",
       "1813           [Luminosité lumineuse]           [Bright luminosity]   \n",
       "1814              [Luminosité neutre]          [Neutral luminosity]   \n",
       "1815              [Luminosité sombre]             [Dark luminosity]   \n",
       "\n",
       "                   additional_info_nl  tokenized_length_fr  \\\n",
       "0               [Bicolor, Rode kleur]                   33   \n",
       "1     [Heldere kleuren, Groene kleur]                   45   \n",
       "2                    [Neutrale kleur]                   40   \n",
       "3                   [Zwart-wit kleur]                   34   \n",
       "4                   [Zwart-wit kleur]                   25   \n",
       "...                               ...                  ...   \n",
       "1811             [Heldere helderheid]                   61   \n",
       "1812            [Neutrale helderheid]                   38   \n",
       "1813             [Heldere helderheid]                   34   \n",
       "1814            [Neutrale helderheid]                   54   \n",
       "1815             [Donkere helderheid]                   44   \n",
       "\n",
       "      tokenized_length_en  tokenized_length_nl  \n",
       "0                      22                   38  \n",
       "1                      34                   47  \n",
       "2                      31                   47  \n",
       "3                      24                   39  \n",
       "4                      18                   26  \n",
       "...                   ...                  ...  \n",
       "1811                   40                   65  \n",
       "1812                   17                   32  \n",
       "1813                   20                   39  \n",
       "1814                   42                   56  \n",
       "1815                   31                   42  \n",
       "\n",
       "[1816 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTING = False\n",
    "if TESTING:\n",
    "    unique_recordIDs = list(DATA['recordID'].unique())\n",
    "    k = 5\n",
    "    first_k_recordIDs = unique_recordIDs[:k]\n",
    "    # Filter DATA to only include the first k recordIDs\n",
    "    filtered_DATA = DATA[DATA['recordID'].isin(first_k_recordIDs)]\n",
    "    DATA = filtered_DATA\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8efb4aa0",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1747314762996,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "8efb4aa0"
   },
   "outputs": [],
   "source": [
    "assert type(example_df[\"additional_info_en\"].values[0]) == list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b39050",
   "metadata": {
    "id": "78b39050"
   },
   "source": [
    "# Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e49ac6",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747314763013,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "b6e49ac6"
   },
   "outputs": [],
   "source": [
    "base_model_february_finetuned = \"openai/clip-vit-large-patch14\" # art-base\n",
    "base_model_march_finetuned = \"openai/clip-vit-large-patch14\" # art-base\n",
    "\n",
    "base_model_mini = \"openai/clip-vit-base-patch32\" # art-mini\n",
    "base_model_base = \"openai/clip-vit-large-patch14\" # art-base\n",
    "base_model_large = \"openai/clip-vit-large-patch14-336\" # art-large\n",
    "\n",
    "basic_mini = \"openai/clip-vit-base-patch32\"\n",
    "basic_base = \"openai/clip-vit-large-patch14\"\n",
    "basic_large = \"openai/clip-vit-large-patch14-336\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45d1b91e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747315423485,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "45d1b91e",
    "outputId": "1c706ab4-d9e0-4710-fe77-7b41ab2e61d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on: art-base-TextFT\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"basic-large\" # OK\n",
    "#model_name = \"art-large\" # OK\n",
    "\n",
    "#model_name = \"art-base\" # OK\n",
    "#model_name = \"basic-base\" # OK\n",
    "#model_name = \"february_finetuned\" # OK\n",
    "#model_name = \"march_finetuned\" # OK\n",
    "\n",
    "#model_name = \"art-mini\" # OK\n",
    "#model_name = \"basic-mini\" # OK\n",
    "model_name = \"art-base-TextFT\"\n",
    "\n",
    "print(f\"Running benchmark on: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd2d0efd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747315423494,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "bd2d0efd"
   },
   "outputs": [],
   "source": [
    "# Create folder to export the results\n",
    "RESULT_FOLDER = \"../benchmarks/benchmark_1\"\n",
    "os.makedirs(RESULT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd68820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../private_data/MODELS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267774f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3695,
     "status": "ok",
     "timestamp": 1747315427197,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "0267774f",
    "outputId": "715fad68-b35c-4d0d-e5ef-13706807ffc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark on: art-base-TextFT with batch size: 2\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"february_finetuned\":\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_base)\n",
    "  model = CLIPModel.from_pretrained(base_model_base).to(device)\n",
    "  model_weights_path = root + \"2025-02-05 17_09_07_allFocus_5.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 2 # 32\n",
    "\n",
    "elif model_name == \"march_finetuned\":\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_base)\n",
    "  model = CLIPModel.from_pretrained(base_model_base).to(device)\n",
    "  model_weights_path = root + \"2025-03-29 16 59 53_allFocus_5.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 2 # 32\n",
    "\n",
    "elif model_name == \"art-mini\":\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_mini)\n",
    "  model = CLIPModel.from_pretrained(base_model_mini).to(device)\n",
    "  model_weights_path = root + \"art-mini.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 8 # 256\n",
    "\n",
    "elif model_name == \"art-base\":\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_base)\n",
    "  model = CLIPModel.from_pretrained(base_model_base).to(device)\n",
    "  model_weights_path = root + \"art-base.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 2 # 32\n",
    "\n",
    "elif model_name == \"art-large\":\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_large)\n",
    "  model = CLIPModel.from_pretrained(base_model_large).to(device)\n",
    "  model_weights_path = root + \"art-large.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 1 # 16\n",
    "\n",
    "elif model_name == \"basic-mini\":\n",
    "  processor = CLIPProcessor.from_pretrained(basic_mini)\n",
    "  model = CLIPModel.from_pretrained(basic_mini).to(device)\n",
    "  BATCH_SIZE = 8 # 256\n",
    "\n",
    "elif model_name == \"basic-base\":\n",
    "  processor = CLIPProcessor.from_pretrained(basic_base)\n",
    "  model = CLIPModel.from_pretrained(basic_base).to(device)\n",
    "  BATCH_SIZE = 2 # 32\n",
    "\n",
    "elif model_name == \"basic-large\":\n",
    "  processor = CLIPProcessor.from_pretrained(basic_large)\n",
    "  model = CLIPModel.from_pretrained(basic_large).to(device)\n",
    "  BATCH_SIZE = 1 # 16\n",
    "else:\n",
    "  processor = CLIPProcessor.from_pretrained(base_model_base)\n",
    "  model = CLIPModel.from_pretrained(base_model_base).to(device)\n",
    "  model_weights_path = root + f\"{model_name}.pt\"\n",
    "  model.load_state_dict(torch.load(model_weights_path, weights_only=True))\n",
    "  BATCH_SIZE = 2 # 32\n",
    "\n",
    "print(f\"Running benchmark on: {model_name} with batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc954d78",
   "metadata": {
    "id": "bc954d78"
   },
   "source": [
    "# Configure the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66a947de",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747315427199,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "66a947de"
   },
   "outputs": [],
   "source": [
    "best_workers = 0\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f5a59",
   "metadata": {
    "id": "ec8f5a59"
   },
   "source": [
    "# Create the -PROMPT and -MIXED datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff3870a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747315427211,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "ff3870a2",
    "outputId": "efb5b20a-cc1c-407a-f9e1-32dc82ccb2f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n"
     ]
    }
   ],
   "source": [
    "artworks_recordIDs = sorted(list(DATA['recordID'].unique()))\n",
    "print(len(artworks_recordIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733198c",
   "metadata": {
    "id": "c733198c"
   },
   "source": [
    "## Create a dataset to compute the embeddings of every image and every text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "234ce694",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26063,
     "status": "ok",
     "timestamp": 1747315453275,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "234ce694",
    "outputId": "40353aed-9115-47d2-a7c4-ce1fbef6289b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing artworks embeddings: 100%|██████████| 227/227 [00:12<00:00, 18.15batch/s]\n"
     ]
    }
   ],
   "source": [
    "class ArtworksImages(Dataset):\n",
    "    def __init__(self, recordIDs):\n",
    "        self.recordIDs = recordIDs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recordIDs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        recordID = self.recordIDs[idx]\n",
    "        path = recordID_to_imageLowResFilename[recordID]\n",
    "\n",
    "        image = Image.open(path)\n",
    "\n",
    "        return image\n",
    "\n",
    "def ArtworksImagesBBuilder(images):\n",
    "    inputs = processor(text=[\"\"] * len(images), images=images, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return inputs\n",
    "\n",
    "artworks_dataset = ArtworksImages(artworks_recordIDs)\n",
    "artworks_dataloader = DataLoader(\n",
    "    artworks_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=best_workers,\n",
    "    collate_fn=ArtworksImagesBBuilder,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "def compute_images_embeddings(dataloader, model, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(dataloader, desc=\"Computing artworks embeddings\", unit=\"batch\"):\n",
    "            input_ids = sample['input_ids'].to(device)\n",
    "            attention_mask = sample['attention_mask'].to(device)\n",
    "            pixel_values = sample['pixel_values'].to(device)\n",
    "\n",
    "            # Compute image embeddings\n",
    "            image_features = model.get_image_features(pixel_values=pixel_values)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            image_features = image_features.flatten(1)\n",
    "\n",
    "            embeddings.append(image_features)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "artworks_embeddings_np_array = compute_images_embeddings(artworks_dataloader, model, device)\n",
    "artworks_embeddings = {}\n",
    "for i, recordID in enumerate(artworks_recordIDs):\n",
    "    artworks_embeddings[recordID] = artworks_embeddings_np_array[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb1ef773",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14125,
     "status": "ok",
     "timestamp": 1747315467414,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "bb1ef773",
    "outputId": "91200353-2c1c-4329-806c-4ec609bbc959"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing captions embeddings: Language: en, Focus: colors: 100%|██████████| 227/227 [00:01<00:00, 117.37batch/s]\n",
      "Computing captions embeddings: Language: en, Focus: content: 100%|██████████| 227/227 [00:01<00:00, 118.14batch/s]\n",
      "Computing captions embeddings: Language: en, Focus: emotion: 100%|██████████| 227/227 [00:01<00:00, 114.47batch/s]\n",
      "Computing captions embeddings: Language: en, Focus: luminosity: 100%|██████████| 227/227 [00:01<00:00, 120.74batch/s]\n",
      "Computing captions embeddings: Language: fr, Focus: colors: 100%|██████████| 227/227 [00:01<00:00, 119.92batch/s]\n",
      "Computing captions embeddings: Language: fr, Focus: content: 100%|██████████| 227/227 [00:01<00:00, 120.36batch/s]\n",
      "Computing captions embeddings: Language: fr, Focus: emotion: 100%|██████████| 227/227 [00:01<00:00, 119.41batch/s]\n",
      "Computing captions embeddings: Language: fr, Focus: luminosity: 100%|██████████| 227/227 [00:01<00:00, 118.45batch/s]\n",
      "Computing captions embeddings: Language: nl, Focus: colors: 100%|██████████| 227/227 [00:01<00:00, 120.52batch/s]\n",
      "Computing captions embeddings: Language: nl, Focus: content: 100%|██████████| 227/227 [00:01<00:00, 120.52batch/s]\n",
      "Computing captions embeddings: Language: nl, Focus: emotion: 100%|██████████| 227/227 [00:01<00:00, 120.20batch/s]\n",
      "Computing captions embeddings: Language: nl, Focus: luminosity: 100%|██████████| 227/227 [00:02<00:00, 113.02batch/s]\n"
     ]
    }
   ],
   "source": [
    "class PromptCaptions(Dataset):\n",
    "    def __init__(self, recordIDs, df, lang, focus):\n",
    "        assert lang in ['en', 'fr', 'nl'], \"Language must be one of ['en', 'fr', 'nl']\"\n",
    "        assert focus in df.focus.unique(), f\"Focus must be one of {df.focus.unique()}\"\n",
    "\n",
    "        self.recordIDs = recordIDs\n",
    "        self.captions = []\n",
    "\n",
    "        rows_with_focus = df[df['focus'] == focus]\n",
    "\n",
    "        for recordID in recordIDs:\n",
    "            row = rows_with_focus[rows_with_focus['recordID'] == recordID].iloc[0] # Should only be one row !\n",
    "            focus = row['focus']\n",
    "            caption = row[f\"caption_{lang}\"]\n",
    "            additional_info = row[f\"additional_info_{lang}\"]\n",
    "\n",
    "            if focus==\"content\":\n",
    "                # additional_info is NaN, we just use the caption\n",
    "                merged_caption = caption\n",
    "            else:\n",
    "                # additional_info is not NaN, we use the caption + additional_info\n",
    "                merged_caption = caption + \" \" + \", \".join(additional_info)\n",
    "\n",
    "            self.captions.append(merged_caption)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.recordIDs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        caption = self.captions[idx]\n",
    "        return caption\n",
    "\n",
    "def PromptCaptionsBBuilder(samples):\n",
    "    inputs = processor(text=samples, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return inputs\n",
    "\n",
    "def compute_captions_embeddings(dataloader, model, device, tqdm_text):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(dataloader, desc=f\"Computing captions embeddings: {tqdm_text}\", unit=\"batch\"):\n",
    "            input_ids = sample['input_ids'].to(device)\n",
    "            attention_mask = sample['attention_mask'].to(device)\n",
    "\n",
    "            # Compute the embeddings\n",
    "            text_features = model.get_text_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "            text_features = text_features.flatten(1)\n",
    "\n",
    "            embeddings.append(text_features)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "prompt_embeddings = {}\n",
    "for lang in ['en', 'fr', 'nl']:\n",
    "    prompt_embeddings[lang] = {}\n",
    "    for focus in unique_focus:\n",
    "        prompt_dataset = PromptCaptions(artworks_recordIDs, DATA, lang, focus)\n",
    "        prompt_dataloader = DataLoader(\n",
    "            prompt_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=best_workers,\n",
    "            collate_fn=PromptCaptionsBBuilder,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        tqdm_text = f\"Language: {lang}, Focus: {focus}\"\n",
    "        raw_embeddings = compute_captions_embeddings(prompt_dataloader, model, device, tqdm_text)\n",
    "        prompt_embeddings[lang][focus] = raw_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9624894",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4522,
     "status": "ok",
     "timestamp": 1747315471948,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "e9624894",
    "outputId": "eae37130-7fcc-4417-b0c5-b1e7a41b3eed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 114.29batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 112.69batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 2/2 [00:00<00:00, 111.12batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 115.94batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 101.27batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 2/2 [00:00<00:00, 114.27batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 117.65batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 4/4 [00:00<00:00, 117.64batch/s]\n",
      "Computing additional informations embeddings: 100%|██████████| 2/2 [00:00<00:00, 121.21batch/s]\n"
     ]
    }
   ],
   "source": [
    "class AdditionalInformation(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.texts[idx]\n",
    "\n",
    "def AdditionalInformationBBuilder(samples):\n",
    "    inputs = processor(text=samples, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    return inputs\n",
    "\n",
    "def compute_additional_infos_embeddings(dataloader, model, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(dataloader, desc=\"Computing additional informations embeddings\", unit=\"batch\"):\n",
    "            input_ids = sample['input_ids'].to(device)\n",
    "            attention_mask = sample['attention_mask'].to(device)\n",
    "\n",
    "            # Compute the embeddings\n",
    "            text_features = model.get_text_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "            text_features = text_features.flatten(1)\n",
    "\n",
    "            embeddings.append(text_features)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "unique_focus_except_content = list(unique_focus.copy())\n",
    "unique_focus_except_content.remove(\"content\")\n",
    "\n",
    "additional_infos_embeddings = {}\n",
    "for lang in ['en', 'fr', 'nl']:\n",
    "    additional_infos_embeddings[lang] = {}\n",
    "    for focus in unique_focus_except_content:\n",
    "\n",
    "        rows_with_focus = DATA[DATA['focus'] == focus]\n",
    "        columnName = f\"additional_info_{lang}\"\n",
    "\n",
    "        unique_additional_infos = set()\n",
    "        for i, row in rows_with_focus.iterrows():\n",
    "          add_info = row[columnName]\n",
    "          for value in add_info:\n",
    "            unique_additional_infos.add(value)\n",
    "\n",
    "        unique_additional_infos = sorted(list(unique_additional_infos))\n",
    "\n",
    "        prompt_dataset = AdditionalInformation(unique_additional_infos)\n",
    "        prompt_dataloader = DataLoader(\n",
    "            prompt_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=best_workers,\n",
    "            collate_fn=AdditionalInformationBBuilder,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        raw_embeddings = compute_additional_infos_embeddings(prompt_dataloader, model, device)\n",
    "        additional_infos_embeddings[lang][focus] = {}\n",
    "        for i, unique_additional_info in enumerate(unique_additional_infos):\n",
    "            additional_infos_embeddings[lang][focus][unique_additional_info] = raw_embeddings[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7362d2b",
   "metadata": {
    "id": "a7362d2b"
   },
   "source": [
    "# Benchmarking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0915462",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747315471964,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "d0915462"
   },
   "outputs": [],
   "source": [
    "def get_average_position(cosine_similarities):\n",
    "    positions = []\n",
    "    average_position = 0\n",
    "    for i in range(len(cosine_similarities)):\n",
    "        sorted_indices = np.argsort(cosine_similarities[i])[::-1]\n",
    "        rank = np.where(sorted_indices == i)[0][0] + 1\n",
    "        sorted_indices = [int(p) for p in sorted_indices]\n",
    "        positions.append(sorted_indices)\n",
    "        average_position += rank\n",
    "    average_position /= len(cosine_similarities)\n",
    "    return average_position, positions\n",
    "\n",
    "def get_MRR(cosine_similarities):\n",
    "    mrr = 0\n",
    "    for i in range(len(cosine_similarities)):\n",
    "        sorted_indices = np.argsort(cosine_similarities[i])[::-1]\n",
    "        rank = np.where(sorted_indices == i)[0][0] + 1\n",
    "        mrr += 1 / rank\n",
    "    mrr /= len(cosine_similarities)\n",
    "    return mrr\n",
    "\n",
    "def get_recall_at_k(cosine_similarities, k):\n",
    "    recall_at_k = 0\n",
    "    for i in range(len(cosine_similarities)):\n",
    "        sorted_indices = np.argsort(cosine_similarities[i])[::-1]\n",
    "        if i in sorted_indices[:k]:\n",
    "            recall_at_k += 1\n",
    "    recall_at_k /= len(cosine_similarities)\n",
    "    return recall_at_k\n",
    "\n",
    "def get_nDCG_at_k(cosine_similarities, k):\n",
    "    nDCG_at_k = 0\n",
    "    for i in range(len(cosine_similarities)):\n",
    "        sorted_indices = np.argsort(cosine_similarities[i])[::-1]\n",
    "        rank = np.where(sorted_indices == i)[0][0] + 1\n",
    "        nDCG_at_k += 1 / np.log2(rank + 1) if rank <= k else 0\n",
    "    nDCG_at_k /= len(cosine_similarities)\n",
    "    return nDCG_at_k\n",
    "\n",
    "def get_metrics_row(cosine_similarities):\n",
    "    recalls_k = [1,3,5,10]\n",
    "    nDCG_k = [1,3,5,10]\n",
    "\n",
    "    average_position, positions = get_average_position(cosine_similarities)\n",
    "    mrr = get_MRR(cosine_similarities)\n",
    "    recalls = [get_recall_at_k(cosine_similarities, k) for k in recalls_k]\n",
    "    nDCGs = [get_nDCG_at_k(cosine_similarities, k) for k in nDCG_k]\n",
    "\n",
    "    metrics = [average_position, mrr] + recalls + nDCGs\n",
    "\n",
    "    return metrics, positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619f924",
   "metadata": {
    "id": "4619f924"
   },
   "source": [
    "# -PROMPT variant\n",
    "Steps:\n",
    "1. For each lang *l*\n",
    "2. For each focus *f*\n",
    "3. Get all the artworks embeddings\n",
    "4. Get all the textual embeddings of the tasks for lang *l* and focus *f*\n",
    "5. Measure the cosine similarity between the artworks and the textual embeddings\n",
    "6. Run the metrics methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae8a4849",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747315471979,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "ae8a4849"
   },
   "outputs": [],
   "source": [
    "def run_prompt_benchmark():\n",
    "    results = pd.DataFrame(columns=[\n",
    "        \"variant\",\n",
    "        \"lang\",\n",
    "        \"focus\",\n",
    "        \"average_position\",\n",
    "        \"mrr\",\n",
    "        \"recall@1\",\n",
    "        \"recall@3\",\n",
    "        \"recall@5\",\n",
    "        \"recall@10\",\n",
    "        \"nDCG@1\",\n",
    "        \"nDCG@3\",\n",
    "        \"nDCG@5\",\n",
    "        \"nDCG@10\"\n",
    "    ])\n",
    "\n",
    "    runs = []\n",
    "    for lang in [\"en\", \"fr\", \"nl\"]:\n",
    "        for focus in unique_focus:\n",
    "            runs.append((lang, focus))\n",
    "\n",
    "    tqdm_bar = tqdm(total=len(runs), desc=\"Running -PROMPT benchmark\", unit=\"run\")\n",
    "\n",
    "    positions_per_lang = {}\n",
    "\n",
    "    for lang, focus in runs:\n",
    "        # Get the artworks embeddings\n",
    "        # Get the textual embeddings of the tasks\n",
    "        textual_embeddings = prompt_embeddings[lang][focus]\n",
    "        # Get the cosine similarities\n",
    "        cosine_similarities = textual_embeddings @ artworks_embeddings_np_array.T\n",
    "        # Measure the metrics\n",
    "        metrics, positions = get_metrics_row(cosine_similarities)\n",
    "\n",
    "        results.loc[len(results)] = [\"-PROMPT\", lang, focus] + metrics\n",
    "        positions_per_lang[(lang, focus)] = positions\n",
    "\n",
    "        tqdm_bar.update(1)\n",
    "        tqdm_bar.set_description(f\"Last result: {lang}-{focus} : MRR: {metrics[1]:.4f}\")\n",
    "\n",
    "    return results, positions_per_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330d7c9",
   "metadata": {
    "id": "d330d7c9"
   },
   "source": [
    "# -MIXED variant\n",
    "Steps:\n",
    "1. For each lang *l*\n",
    "2. For each focus *f* (except *f=content*)\n",
    "3. Get all the artworks embeddings\n",
    "4. For a task $t=(l,f,recordID)$, get the textual embedding of the caption $c$ and the textual embeddings of the $n$ additional information $a_{i \\in \\{1,2,\\ldots,n\\}}$\n",
    "5. Mix $c$ and the $a$ embeddings\n",
    "6. Normalize the mixed embedding\n",
    "7. Measure the cosine similarity between the artworks and the mixed embeddings\n",
    "8. Run the metrics methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b579026d",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747315471983,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "b579026d"
   },
   "outputs": [],
   "source": [
    "def run_mixed_benchmark():\n",
    "    results = pd.DataFrame(columns=[\n",
    "        \"variant\",\n",
    "        \"lang\",\n",
    "        \"focus\",\n",
    "        \"average_position\",\n",
    "        \"mrr\",\n",
    "        \"recall@1\",\n",
    "        \"recall@3\",\n",
    "        \"recall@5\",\n",
    "        \"recall@10\",\n",
    "        \"nDCG@1\",\n",
    "        \"nDCG@3\",\n",
    "        \"nDCG@5\",\n",
    "        \"nDCG@10\"\n",
    "    ])\n",
    "\n",
    "    runs = []\n",
    "    for lang in [\"en\", \"fr\", \"nl\"]:\n",
    "        for focus in unique_focus_except_content:\n",
    "            runs.append((lang, focus))\n",
    "\n",
    "    tqdm_bar = tqdm(total=len(runs), desc=\"Running -MIXED benchmark\", unit=\"run\")\n",
    "\n",
    "    positions_per_lang = {}\n",
    "\n",
    "    for lang, focus in runs:\n",
    "        # Get the artworks embeddings\n",
    "\n",
    "        # Get the mixed embeddings of the tasks\n",
    "        rows_focus = DATA[DATA['focus'] == focus]\n",
    "        mixed_embeddings = []\n",
    "\n",
    "        caption_embeddings = prompt_embeddings[lang][\"content\"] # We always use the content captions as it is not merged with additional info :)\n",
    "        for recordID in artworks_recordIDs:\n",
    "            row_recordID = rows_focus[rows_focus['recordID'] == recordID].iloc[0] # Should only be one row !\n",
    "            additional_info_values = row_recordID[f\"additional_info_{lang}\"]\n",
    "\n",
    "            recordID_index = artworks_recordIDs.index(recordID)\n",
    "            caption_embedding = caption_embeddings[recordID_index]\n",
    "\n",
    "            all_embeddings_for_recordID = [caption_embedding]\n",
    "            for additional_info in additional_info_values:\n",
    "                additional_info_embdding = additional_infos_embeddings[lang][focus][additional_info]\n",
    "                all_embeddings_for_recordID.append(additional_info_embdding)\n",
    "\n",
    "            # Convert all_embeddings_for_recordID to torch\n",
    "            all_embeddings_for_recordID = [torch.from_numpy(emb) for emb in all_embeddings_for_recordID]\n",
    "\n",
    "            # Get the average of the embeddings\n",
    "            mixed_embedding = torch.mean(torch.stack(all_embeddings_for_recordID), dim=0)\n",
    "            # Normalize the embedding\n",
    "            mixed_embedding = mixed_embedding / mixed_embedding.norm(dim=-1, keepdim=True)\n",
    "            mixed_embeddings.append(mixed_embedding)\n",
    "\n",
    "        mixed_embeddings = torch.stack(mixed_embeddings)\n",
    "        mixed_embeddings = np.array(mixed_embeddings)\n",
    "\n",
    "        # Get the cosine similarities\n",
    "        cosine_similarities = mixed_embeddings @ artworks_embeddings_np_array.T\n",
    "        # Measure the metrics\n",
    "        metrics, positions = get_metrics_row(cosine_similarities)\n",
    "\n",
    "        results.loc[len(results)] = [\"-MIXED\", lang, focus] + metrics\n",
    "        positions_per_lang[(lang, focus)] = positions\n",
    "\n",
    "        tqdm_bar.update(1)\n",
    "        tqdm_bar.set_description(f\"Last result: {lang}-{focus} : MRR: {metrics[1]:.4f}\")\n",
    "\n",
    "    return results, positions_per_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4d7024e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1747315479299,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "b4d7024e",
    "outputId": "acef58a3-63b1-4147-a54d-73aa1329dffd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Last result: nl-luminosity : MRR: 0.0488: 100%|██████████| 12/12 [00:00<00:00, 12.00run/s]\n",
      "Last result: nl-luminosity : MRR: 0.0322: 100%|██████████| 9/9 [00:01<00:00,  4.81run/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>lang</th>\n",
       "      <th>focus</th>\n",
       "      <th>average_position</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>nDCG@3</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>en</td>\n",
       "      <td>colors</td>\n",
       "      <td>11.422907</td>\n",
       "      <td>0.511141</td>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.605727</td>\n",
       "      <td>0.696035</td>\n",
       "      <td>0.801762</td>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.503772</td>\n",
       "      <td>0.540639</td>\n",
       "      <td>0.574943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>en</td>\n",
       "      <td>content</td>\n",
       "      <td>10.779736</td>\n",
       "      <td>0.506275</td>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.605727</td>\n",
       "      <td>0.685022</td>\n",
       "      <td>0.797357</td>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.500311</td>\n",
       "      <td>0.532724</td>\n",
       "      <td>0.569507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>en</td>\n",
       "      <td>emotion</td>\n",
       "      <td>15.383260</td>\n",
       "      <td>0.438448</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.519824</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.422590</td>\n",
       "      <td>0.466080</td>\n",
       "      <td>0.503758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>en</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>15.030837</td>\n",
       "      <td>0.454326</td>\n",
       "      <td>0.312775</td>\n",
       "      <td>0.524229</td>\n",
       "      <td>0.618943</td>\n",
       "      <td>0.762115</td>\n",
       "      <td>0.312775</td>\n",
       "      <td>0.435517</td>\n",
       "      <td>0.474378</td>\n",
       "      <td>0.520435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>fr</td>\n",
       "      <td>colors</td>\n",
       "      <td>110.162996</td>\n",
       "      <td>0.082663</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.077093</td>\n",
       "      <td>0.107930</td>\n",
       "      <td>0.151982</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.085649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>fr</td>\n",
       "      <td>content</td>\n",
       "      <td>103.975771</td>\n",
       "      <td>0.091934</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.121145</td>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.081397</td>\n",
       "      <td>0.096577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>fr</td>\n",
       "      <td>emotion</td>\n",
       "      <td>116.502203</td>\n",
       "      <td>0.070786</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.063877</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>0.136564</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.048563</td>\n",
       "      <td>0.055959</td>\n",
       "      <td>0.073835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>fr</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>117.070485</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.143172</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.044393</td>\n",
       "      <td>0.060986</td>\n",
       "      <td>0.076548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>nl</td>\n",
       "      <td>colors</td>\n",
       "      <td>138.444934</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.030076</td>\n",
       "      <td>0.036331</td>\n",
       "      <td>0.048603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>nl</td>\n",
       "      <td>content</td>\n",
       "      <td>133.028634</td>\n",
       "      <td>0.056834</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.092511</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>0.041632</td>\n",
       "      <td>0.053112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>nl</td>\n",
       "      <td>emotion</td>\n",
       "      <td>142.544053</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.077093</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.034779</td>\n",
       "      <td>0.045063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-PROMPT</td>\n",
       "      <td>nl</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>140.242291</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.035946</td>\n",
       "      <td>0.046763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>en</td>\n",
       "      <td>colors</td>\n",
       "      <td>34.255507</td>\n",
       "      <td>0.317034</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>0.378855</td>\n",
       "      <td>0.466960</td>\n",
       "      <td>0.603524</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.332331</td>\n",
       "      <td>0.376024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>en</td>\n",
       "      <td>emotion</td>\n",
       "      <td>38.079295</td>\n",
       "      <td>0.227713</td>\n",
       "      <td>0.125551</td>\n",
       "      <td>0.240088</td>\n",
       "      <td>0.332599</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.125551</td>\n",
       "      <td>0.191760</td>\n",
       "      <td>0.229285</td>\n",
       "      <td>0.262228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>en</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>46.339207</td>\n",
       "      <td>0.247276</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.281938</td>\n",
       "      <td>0.359031</td>\n",
       "      <td>0.449339</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.221836</td>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.282744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>fr</td>\n",
       "      <td>colors</td>\n",
       "      <td>144.057269</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.057269</td>\n",
       "      <td>0.096916</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.036436</td>\n",
       "      <td>0.049325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>fr</td>\n",
       "      <td>emotion</td>\n",
       "      <td>168.129956</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.063877</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.032239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>fr</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>154.892070</td>\n",
       "      <td>0.040233</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.044053</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.040068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>nl</td>\n",
       "      <td>colors</td>\n",
       "      <td>166.863436</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.030295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>nl</td>\n",
       "      <td>emotion</td>\n",
       "      <td>169.856828</td>\n",
       "      <td>0.029040</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.026031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-MIXED</td>\n",
       "      <td>nl</td>\n",
       "      <td>luminosity</td>\n",
       "      <td>166.724670</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.030286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variant lang       focus  average_position       mrr  recall@1  recall@3  \\\n",
       "0   -PROMPT   en      colors         11.422907  0.511141  0.356828  0.605727   \n",
       "1   -PROMPT   en     content         10.779736  0.506275  0.356828  0.605727   \n",
       "2   -PROMPT   en     emotion         15.383260  0.438448  0.290749  0.519824   \n",
       "3   -PROMPT   en  luminosity         15.030837  0.454326  0.312775  0.524229   \n",
       "4   -PROMPT   fr      colors        110.162996  0.082663  0.035242  0.077093   \n",
       "5   -PROMPT   fr     content        103.975771  0.091934  0.041850  0.083700   \n",
       "6   -PROMPT   fr     emotion        116.502203  0.070786  0.028634  0.063877   \n",
       "7   -PROMPT   fr  luminosity        117.070485  0.073006  0.030837  0.055066   \n",
       "8   -PROMPT   nl      colors        138.444934  0.050200  0.019824  0.037445   \n",
       "9   -PROMPT   nl     content        133.028634  0.056834  0.028634  0.039648   \n",
       "10  -PROMPT   nl     emotion        142.544053  0.049350  0.022026  0.037445   \n",
       "11  -PROMPT   nl  luminosity        140.242291  0.048804  0.019824  0.037445   \n",
       "12   -MIXED   en      colors         34.255507  0.317034  0.182819  0.378855   \n",
       "13   -MIXED   en     emotion         38.079295  0.227713  0.125551  0.240088   \n",
       "14   -MIXED   en  luminosity         46.339207  0.247276  0.140969  0.281938   \n",
       "15   -MIXED   fr      colors        144.057269  0.048243  0.017621  0.033040   \n",
       "16   -MIXED   fr     emotion        168.129956  0.034157  0.013216  0.022026   \n",
       "17   -MIXED   fr  luminosity        154.892070  0.040233  0.013216  0.026432   \n",
       "18   -MIXED   nl      colors        166.863436  0.032602  0.008811  0.028634   \n",
       "19   -MIXED   nl     emotion        169.856828  0.029040  0.006608  0.019824   \n",
       "20   -MIXED   nl  luminosity        166.724670  0.032207  0.008811  0.022026   \n",
       "\n",
       "    recall@5  recall@10    nDCG@1    nDCG@3    nDCG@5   nDCG@10  \n",
       "0   0.696035   0.801762  0.356828  0.503772  0.540639  0.574943  \n",
       "1   0.685022   0.797357  0.356828  0.500311  0.532724  0.569507  \n",
       "2   0.627753   0.742291  0.290749  0.422590  0.466080  0.503758  \n",
       "3   0.618943   0.762115  0.312775  0.435517  0.474378  0.520435  \n",
       "4   0.107930   0.151982  0.035242  0.059051  0.071560  0.085649  \n",
       "5   0.121145   0.169604  0.041850  0.066236  0.081397  0.096577  \n",
       "6   0.081498   0.136564  0.028634  0.048563  0.055959  0.073835  \n",
       "7   0.094714   0.143172  0.030837  0.044393  0.060986  0.076548  \n",
       "8   0.052863   0.090308  0.019824  0.030076  0.036331  0.048603  \n",
       "9   0.057269   0.092511  0.028634  0.034429  0.041632  0.053112  \n",
       "10  0.046256   0.077093  0.022026  0.031178  0.034779  0.045063  \n",
       "11  0.052863   0.085903  0.019824  0.029788  0.035946  0.046763  \n",
       "12  0.466960   0.603524  0.182819  0.295833  0.332331  0.376024  \n",
       "13  0.332599   0.436123  0.125551  0.191760  0.229285  0.262228  \n",
       "14  0.359031   0.449339  0.140969  0.221836  0.253397  0.282744  \n",
       "15  0.057269   0.096916  0.017621  0.026484  0.036436  0.049325  \n",
       "16  0.033040   0.063877  0.013216  0.018198  0.022651  0.032239  \n",
       "17  0.044053   0.081498  0.013216  0.020689  0.028085  0.040068  \n",
       "18  0.033040   0.061674  0.008811  0.019299  0.021197  0.030295  \n",
       "19  0.030837   0.052863  0.006608  0.014369  0.018920  0.026031  \n",
       "20  0.033040   0.061674  0.008811  0.016284  0.020834  0.030286  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the benchmarks !\n",
    "import pickle\n",
    "\n",
    "results_prompt, positions_prompt = run_prompt_benchmark()\n",
    "results_mixed, positions_mixed = run_mixed_benchmark()\n",
    "results = pd.concat([results_prompt, results_mixed], ignore_index=True)\n",
    "results.to_csv(RESULT_FOLDER + f\"/{model_name}_benchmark.csv\", index=False)\n",
    "# Save positions_prompt\n",
    "with open(RESULT_FOLDER + f\"/{model_name}_positions_prompt.pkl\", \"wb\") as f:\n",
    "    pickle.dump(positions_prompt, f)\n",
    "with open(RESULT_FOLDER + f\"/{model_name}_positions_mixed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(positions_mixed, f)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tu83uwrOwxl2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1747315479353,
     "user": {
      "displayName": "V R",
      "userId": "13450465406636340234"
     },
     "user_tz": -120
    },
    "id": "tu83uwrOwxl2",
    "outputId": "48bf1672-768f-4b5c-9d30-55ca01518b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('en', 'colors'): 454x454\n",
      "('en', 'content'): 454x454\n",
      "('en', 'emotion'): 454x454\n",
      "('en', 'luminosity'): 454x454\n",
      "('fr', 'colors'): 454x454\n",
      "('fr', 'content'): 454x454\n",
      "('fr', 'emotion'): 454x454\n",
      "('fr', 'luminosity'): 454x454\n",
      "('nl', 'colors'): 454x454\n",
      "('nl', 'content'): 454x454\n",
      "('nl', 'emotion'): 454x454\n",
      "('nl', 'luminosity'): 454x454\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test load the pkl\n",
    "with open(RESULT_FOLDER + f\"/{model_name}_positions_prompt.pkl\", \"rb\") as f:\n",
    "    positions_prompt = pickle.load(f)\n",
    "\n",
    "for key in positions_prompt.keys():\n",
    "  lens = len(positions_prompt[key])\n",
    "  lens_d2 = len(positions_prompt[key][0])\n",
    "  print(f\"{key}: {lens}x{lens_d2}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
